{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "# Convolutional neural network\r\n",
    "# Made up of neurons\r\n",
    "# Applies convolutional filters"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import torch\r\n",
    "import torch.nn as nn\r\n",
    "import torch.nn.functional as F\r\n",
    "import torchvision\r\n",
    "import torchvision.transforms as transforms\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Device, gpu\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "print(device)\r\n",
    "\r\n",
    "#Hyper params\r\n",
    "num_epochs = 2\r\n",
    "batch_size = 1\r\n",
    "learning_rate = 0.001"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\r\n",
    "\r\n",
    "train_datasets = torchvision.datasets.MNIST(root='./data', train=True,transform=transforms.ToTensor(), download=True)\r\n",
    "test_datasets = torchvision.datasets.MNIST(root='./data', train=False,transform=transforms.ToTensor())\r\n",
    "\r\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_datasets, batch_size=batch_size, shuffle=True)\r\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_datasets, batch_size=batch_size, shuffle=False)\r\n",
    "\r\n",
    "classes = ('0', '1', '2', '3', '4', '5', '6', '7', '8', '9')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "9913344it [00:00, 11414068.16it/s]                             \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "29696it [00:00, 29691073.08it/s]         \n",
      "  0%|          | 0/1648877 [00:00<?, ?it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "1649664it [00:00, 9205803.41it/s]                            \n",
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "C:\\Users\\Morten\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class ConvNet(nn.Module):\r\n",
    "    def __init__(self):\r\n",
    "        super(ConvNet, self).__init__()\r\n",
    "        #Colors: 3, output: 6, kernel_size: 5\r\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\r\n",
    "        #kernel_size: 2, stride: 2\r\n",
    "        self.pool = nn.MaxPool2d(2)\r\n",
    "        #Input = conv1 output som er 6\r\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\r\n",
    "        self.fc1 = nn.Linear(64*2*2, 120)\r\n",
    "        self.fc2 = nn.Linear(120, 84)\r\n",
    "        self.fc3 = nn.Linear(84, 10)\r\n",
    "    def forward(self,x):\r\n",
    "        x = self.pool(F.relu(self.conv1(x)))\r\n",
    "        x = self.pool(F.relu(self.conv2(x)))\r\n",
    "        x = x.view(-1, 64*2*2)\r\n",
    "        x = F.relu(self.fc1(x))\r\n",
    "        x = F.relu(self.fc2(x))\r\n",
    "        x = self.fc3(x)\r\n",
    "        return x\r\n",
    "\r\n",
    "model = ConvNet().to(device)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "#Loss\r\n",
    "criterion = nn.CrossEntropyLoss()\r\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "n_total_steps = len(train_loader)\r\n",
    "for epoch in range(num_epochs):\r\n",
    "    for i, (images, labels) in enumerate(train_loader):\r\n",
    "        images = images.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "\r\n",
    "        #forward pass\r\n",
    "        outputs = model(images)\r\n",
    "        loss = criterion(outputs,labels)\r\n",
    "\r\n",
    "        #backward pass and optimize\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        if(i+1) % 10000 == 0:\r\n",
    "            print(f'epoch {epoch+1} / {num_epochs}, step {i+1}/{n_total_steps}, loss = {loss.item():.4f}')\r\n",
    "\r\n",
    "print('Finished Training')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Morten\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch 1 / 2, step 10000/60000, loss = 1.1327\n",
      "epoch 1 / 2, step 20000/60000, loss = 0.1995\n",
      "epoch 1 / 2, step 30000/60000, loss = 0.1608\n",
      "epoch 1 / 2, step 40000/60000, loss = 0.0024\n",
      "epoch 1 / 2, step 50000/60000, loss = 0.0001\n",
      "epoch 1 / 2, step 60000/60000, loss = 0.0005\n",
      "epoch 2 / 2, step 10000/60000, loss = 0.0002\n",
      "epoch 2 / 2, step 20000/60000, loss = 0.0000\n",
      "epoch 2 / 2, step 30000/60000, loss = 0.0064\n",
      "epoch 2 / 2, step 40000/60000, loss = 0.0003\n",
      "epoch 2 / 2, step 50000/60000, loss = 0.0001\n",
      "epoch 2 / 2, step 60000/60000, loss = 0.0191\n",
      "Finished Training\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#test\r\n",
    "with torch.no_grad():\r\n",
    "    n_correct = 0\r\n",
    "    n_samples = 0\r\n",
    "    n_class_correct = [0 for i in range(10)]\r\n",
    "    n_class_samples = [0 for i in range(10)]\r\n",
    "    for images, labels in test_loader:\r\n",
    "        images = images.to(device)\r\n",
    "        labels = labels.to(device)\r\n",
    "        outputs = model(images)\r\n",
    "\r\n",
    "        _, predicted = torch.max(outputs,1)\r\n",
    "        n_samples += labels.shape[0]\r\n",
    "        n_correct += (predicted == labels).sum().item()\r\n",
    "\r\n",
    "        for i in range(batch_size):\r\n",
    "            label = labels[i]\r\n",
    "            pred = predicted[i]\r\n",
    "            if(label == pred):\r\n",
    "                n_class_correct[label] += 1\r\n",
    "            n_class_samples[label] += 1\r\n",
    "\r\n",
    "acc = 100.0 *n_correct/n_samples\r\n",
    "print(f'Accuracy = {acc}')\r\n",
    "\r\n",
    "for i in range(10):\r\n",
    "    acc = 100.0 * n_class_correct[i] / n_class_samples[i]\r\n",
    "    print(f'Accuracy of {classes[i]}: {acc} %')\r\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy = 97.74\n",
      "Accuracy of 0: 99.59183673469387 %\n",
      "Accuracy of 1: 99.8237885462555 %\n",
      "Accuracy of 2: 97.67441860465117 %\n",
      "Accuracy of 3: 97.72277227722772 %\n",
      "Accuracy of 4: 98.67617107942974 %\n",
      "Accuracy of 5: 95.96412556053812 %\n",
      "Accuracy of 6: 97.07724425887265 %\n",
      "Accuracy of 7: 97.56809338521401 %\n",
      "Accuracy of 8: 97.12525667351129 %\n",
      "Accuracy of 9: 95.73835480673935 %\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "8b7a5e7e088dc87b16d72ecb84aa6dc0c370a308eb78f8481e88a4680c33e6f1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}